% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_model5.R
\name{cross_validate_model5}
\alias{cross_validate_model5}
\title{Cross-validate model 5}
\usage{
cross_validate_model5(
  dat,
  response_name,
  outer_cv_folds = 3,
  inner_cv_folds = 3,
  calibration_youden_index_threshold = 0.9,
  calibration_lambda_min_ratio = 1e-06,
  random_state = 56,
  mtry = NULL,
  save_level = 3,
  save_prefix = "train_model5_",
  overwrite = FALSE,
  output = NULL,
  verbose = TRUE
)
}
\arguments{
\item{dat}{a \code{data.frame} of input data.}

\item{response_name}{column name of the response.}

\item{outer_cv_folds}{outer cross-validation fold number.}

\item{inner_cv_folds}{inner cross-validation fold number.}

\item{calibration_youden_index_threshold}{a float of Youden index threhold.
Default to 0.9.}

\item{calibration_lambda_min_ratio}{see \code{lambda.min.ratio} of
\code{\link[glmnet]{glmnet}}. Default to 1e-6.}

\item{random_state}{random seed.}

\item{mtry}{A vector of mtry for parameter tuning.}

\item{save_level}{if save_level > 0, save outer train index. If save_level > 1,
save calibrated probabilities and selected features in addition.}

\item{save_prefix}{output file prefix.}

\item{overwrite}{overwrite existing result files or not.}

\item{output}{output directory.}

\item{verbose}{A bool.}

\item{feature_selection}{feature selection method.}
}
\value{
a list of cross-validation result of given \code{mtry} values.
}
\description{
Similar to model 1, but with tentative features from Boruta.
}
\details{
Key steps:
  \enumerate{
    \item Tuning loop tunes single parameter \code{mtry}.
    \item Outer cross-validation split the data set into training and testing
      set of M folds.
    \item Inner cross-validation split the training set of the outer CV into
      N folds. Each fold does the feature selection with Boruta algorithm and
      random forest classification. When all folds are done. Train calibration
      model of Ridge multinomial logistic regression (MR) regression. The
      lambda is trained with \code{\link[glmnet]{cv.glmnet}}. The random
      forest and calibration models are used for the testing set of the outer
      CV.
  }
}
