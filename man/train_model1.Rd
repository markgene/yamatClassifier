% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/train_model1.R
\name{train_model1}
\alias{train_model1}
\title{Train model 1}
\usage{
train_model1(
  dat,
  response_name,
  feature_selection = c("Boruta"),
  outer_cv_folds = 5,
  inner_cv_folds = 5,
  random_state = 56,
  mtry = NULL,
  verbose = TRUE
)
}
\arguments{
\item{dat}{a \code{data.frame} of input data.}

\item{response_name}{column name of the response.}

\item{feature_selection}{feature selection method.}

\item{outer_cv_folds}{outer cross-validation fold number.}

\item{inner_cv_folds}{inner cross-validation fold number.}

\item{random_state}{random seed.}

\item{mtry}{A vector of mtry for parameter tuning.}

\item{verbose}{A bool.}
}
\value{
a list of cross-validation result of given \code{mtry} values.
}
\description{
Train model 1
}
\details{
Key steps:
  \enumerate{
    \item Tuning loop tunes single parameter \code{mtry}.
    \item Outer cross-validation split the data set into training and testing
      set of M folds.
    \item Inner cross-validation split the training set of the outer CV into
      N folds. Each fold does the feature selection with Boruta algorithm and
      random forest classification. When all folds are done. Train calibration
      model of Ridge multinomial logistic regression (MR) regression. The
      lambda is trained with \code{\link[glmnet]{cv.glmnet}}. The random
      forest and calibration models are used for the testing set of the outer
      CV.
  }
}
